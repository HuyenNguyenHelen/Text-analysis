## Extract metadata :\\
## Fix forbidden errors
## Building a program for downloading metadata, using id
# HelenNguyen
### Example of UNT library
import ssl
from bs4 import BeautifulSoup
import urllib.request
import requests

ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE


f_id =urllib.request.urlopen("https://digital.library.unt.edu/search/?t=fulltext&t1=dc_title&t2=dc_description&t3=untl_agent&t4=dc_publisher&q5=%28information+science%29&t5=dc_subject&t6=dc_coverage&t7=dc_identifier&t8=page&sort=default&searchType=advanced&fq=untl_collection%3AUNTETD&fq=untl_decade%3A2010-2019&fq=str_degree_level%3ADoctoral")
webpage = f_id.read()
soup = BeautifulSoup(webpage)
#print(soup)
id_list = []
for i in range (1, 25):
  for tag in soup.find_all('a', id="result-title-"+str(i)):
    id_list.append(tag.get("data-meta-id"))
#print(id_list)
#https://digital.library.unt.edu/ark:/67531/metadc1248497/metadata.dc.json
parse_link_begin = "https://digital.library.unt.edu/ark:/67531/"
parse_link_end = "/metadata.dc.json"
f_link=[]
for id in id_list:
  f_link.append(parse_link_begin+id+parse_link_end)
#print(f_link)
fjson_list=[]
for link in f_link:
  open_link = urllib.request.urlopen(link)
  webpage = open_link.read()
  soup = BeautifulSoup(webpage)
  for json in soup:
    fjson_list.append(json)
print (len(fjson_list))
print(fjson_list[0])
    
